{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Embedding Function from Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "def get_embedding_function():\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up ChromaDB for Vector Database & Separate the Document into Chunks Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"data\"\n",
    "\n",
    "def main(reset=False):  # Add reset as a function argument\n",
    "    # Check if the database should be reset (manual argument)\n",
    "    if reset:\n",
    "        print(\"Clearing Database...\")\n",
    "        clear_database()\n",
    "\n",
    "    # Continue processing documents\n",
    "    documents = load_documents()\n",
    "    chunks = split_documents(documents)\n",
    "    add_to_chroma(chunks)\n",
    "\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"Adding new documents: {len(new_chunks)}...\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"No new documents to add\")\n",
    "\n",
    "def calculate_chunk_ids(chunks):\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_30464\\485711348.py:41: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 0\n",
      "üëâ Adding new documents: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_30464\\485711348.py:63: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "main(reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embedding_function()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    print(prompt)\n",
    "\n",
    "    model = Ollama(model=\"llama3\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the RAG Improved LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "HaÔ¨Ådh Husna | Rekayasa Perangkat Lunak  Indust ri / Pengirim Sampah, Pengepul / Penerima Sampah, Kurir, dan Pengguna \n",
      "Umum. Setiap role memiliki akses Ô¨Åtur aplikasi yang berbeda, tetapi selu ruh role \n",
      "dapat mengakses artikel edukasi yang dipublikasikan oleh admin dan pengguna \n",
      "umum. Role sebagai pelaku industr i / pengirim sampah memiliki akses  di mana \n",
      "pengguna dapat melakukan permintaan pengiriman sampah dau r ulang serta dapat \n",
      "melakukan real time tracking terhadap proses pengirimannya. K emudian  role \n",
      "sebagai pengepul / penerima sampah memiliki akses  di mana pengguna dapat \n",
      "menerima permintaan pengiriman sampah daur ulang dari pelaku indust ri / pengirim \n",
      "sampah  serta me lakukan real t ime tracking terhadap proses pengirimannya.\n",
      "\n",
      "---\n",
      "\n",
      "sampah  serta me lakukan real t ime tracking terhadap proses pengirimannya. \n",
      "Selanjutnya role sebagai kurir d apat menerima permintaan pengiriman sampah dari \n",
      "pelaku industri  dan telah disetujui oleh penerima / pengepul sampah . Dalam \n",
      "aplikasi ini, terdapat admin DAUR yang memiliki peran utama publikasi artikel \n",
      "edukasi . Selain admin, pengguna umum juga dapat melakukan publikasi artikel \n",
      "edukasi, tetapi membutuhkan veriÔ¨Åkasi dari admin untuk tiap artikel yang ingin \n",
      "dipublikasi.\n",
      "\n",
      "---\n",
      "\n",
      "2. Permintaan mengirim sampah oleh pelaku industri \n",
      "3. Permintaan menerima sampah oleh pengepul sampah  \n",
      "4. Tracking proses pengiriman sampah baik oleh pelaku industri maupun pengepul \n",
      "sampah  \n",
      "5. Publikasi artikel edukasi yang dilakukan oleh admin aplikasi dan pengguna umum  \n",
      "6. VeriÔ¨Åkasi publikasi artikel edukasi oleh admin  \n",
      "7. Membaca artikel edukasi yang dapat dilakukan oleh semua role  \n",
      "8. Penerimaan pengiriman sampah oleh kurir \n",
      "II. Functional Requirements  \n",
      "1. Aplikasi memungkinkan pengguna untuk melakukan pendaftaran sebagai pelaku \n",
      "industri / pengirim sampah, penerima sampah, kurir, atau sebagai pengguna \n",
      "umum  \n",
      "2. Pelaku industri / pengirim sampah dapat melakukan permintaan pengiriman \n",
      "sampah  \n",
      "3. Penerima / pengepul sampah dapat menerima permintaan pengiriman sampah\n",
      "\n",
      "---\n",
      "\n",
      "ingin menga ksesnya  \n",
      "2. Keamanan data penggun yang terjamin dengan enkripsi  \n",
      "3. Maintenance berkala supaya memastikan aplikasi dapat berjalan dengan lancer  \n",
      "secara kontinu.  \n",
      "IV. Use Case Diagram  \n",
      " \n",
      "Use case diagram untuk aplikasi ini meliputi interaksi antar dua  aktor, yaitu \n",
      "pengguna / user dan admin. P engguna dapat melakukan registrasi yang di dalam nya \n",
      "termasuk memilih salah satu dari empa t role yang telah disediakan, yaitu Pelaku\n",
      "\n",
      "---\n",
      "\n",
      "HaÔ¨Ådh Husna | Rekayasa Perangkat Lunak  HaÔ¨Ådh Husna  ‚Äì 22/498640/TK/54706  \n",
      " \n",
      "Tugas 3 Rekayasa Perangkat Lunak  \n",
      "Functional & Non-Functional Requirements Aplikasi pada Praktikum Junior Project  \n",
      "I. Deskripsi Rancangan Aplikasi  \n",
      "Platform manajemen limbah daur ulang bernama DAUR berbasis windows form \n",
      "desktop app yang memiliki fungsi utama untuk menghubungkan industri -industri \n",
      "penghasil limbah yang dapat didaur ulang kepada penampung/pengepul sampah. \n",
      "Platform ini dikembangkan menggunakan bahasa C# dengan Visual Studio 2022 \n",
      "sebagai tools pembuatannya. Aplikasi ini menawarkan beberapa Ô¨Åtur utama :  \n",
      "1. Registrasi akun, pengguna dapat mendaftar dan memilih sebagai pelaku industri \n",
      "(pengirim sampah), pengepul/penerima sampah daur ulang, kurir pengirim sampah, atau sebagai pengguna umum\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: What is the functional requirements in the DAUR?\n",
      "\n",
      "Response: Based on the provided context, the functional requirements of the DAUR application are:\n",
      "\n",
      "1. Aplikasi memungkinkan pengguna untuk melakukan pendaftaran sebagai pelaku industri / pengirim sampah, penerima sampah, kurir, atau sebagai pengguna umum\n",
      "2. Pelaku industri / pengirim sampah dapat melakukan permintaan pengiriman sampah\n",
      "3. Penerima / pengepul sampah dapat menerima permintaan pengiriman sampah\n",
      "4. Tracking proses pengiriman sampah baik oleh pelaku industri maupun pengepul sampah\n",
      "5. Publikasi artikel edukasi yang dilakukan oleh admin aplikasi dan pengguna umum\n",
      "6. VeriÔ¨Åkasi publikasi artikel edukasi oleh admin\n",
      "7. Membaca artikel edukasi yang dapat dilakukan oleh semua role\n",
      "Sources: ['data\\\\498640_Hafidh Husna_Tugas 3 RPL.pdf:2:0', 'data\\\\498640_Hafidh Husna_Tugas 3 RPL.pdf:2:1', 'data\\\\498640_Hafidh Husna_Tugas 3 RPL.pdf:0:1', 'data\\\\498640_Hafidh Husna_Tugas 3 RPL.pdf:1:1', 'data\\\\498640_Hafidh Husna_Tugas 3 RPL.pdf:0:0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the functional requirements of the DAUR application are:\\n\\n1. Aplikasi memungkinkan pengguna untuk melakukan pendaftaran sebagai pelaku industri / pengirim sampah, penerima sampah, kurir, atau sebagai pengguna umum\\n2. Pelaku industri / pengirim sampah dapat melakukan permintaan pengiriman sampah\\n3. Penerima / pengepul sampah dapat menerima permintaan pengiriman sampah\\n4. Tracking proses pengiriman sampah baik oleh pelaku industri maupun pengepul sampah\\n5. Publikasi artikel edukasi yang dilakukan oleh admin aplikasi dan pengguna umum\\n6. VeriÔ¨Åkasi publikasi artikel edukasi oleh admin\\n7. Membaca artikel edukasi yang dapat dilakukan oleh semua role'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call the query_rag function directly\n",
    "query_text = \"What is the functional requirements in the DAUR?\"\n",
    "query_rag(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PROMPT = \"\"\"\n",
    "Expected Response: {expected_response}\n",
    "Actual Response: {actual_response}\n",
    "---\n",
    "(Answer with 'true' or 'false') Does the actual response match the expected response? \n",
    "\"\"\"\n",
    "\n",
    "def query_and_validate(question: str, expected_response: str):\n",
    "    response_text = query_rag(question)\n",
    "    prompt = EVAL_PROMPT.format(\n",
    "        expected_response=expected_response, actual_response=response_text\n",
    "    )\n",
    "\n",
    "    model = Ollama(model=\"llama3\")\n",
    "    evaluation_results_str = model.invoke(prompt)\n",
    "    evaluation_results_str_cleaned = evaluation_results_str.strip().lower()\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    if \"true\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Green if it is correct.\n",
    "        print(\"\\033[92m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return True\n",
    "    elif \"false\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Red if it is incorrect.\n",
    "        print(\"\\033[91m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid evaluation result. Cannot determine if 'true' or 'false'.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Software Functional Requirements (Software Engineering Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_software_functional_requirements():\n",
    "    assert query_and_validate(\n",
    "        question=\"What is the functional requirements in the DAUR?\",\n",
    "        expected_response=\"\"\"1. Aplikasi memungkinkan pengguna untuk melakukan pendaftaran sebagai pelaku \n",
    "industri  /  pengirim  sampah,  penerima  sampah,  kurir,  atau  sebagai  pengguna  \n",
    "umum 2. Pelaku  industri  /  pengirim  sampah  dapat  melakukan  permintaan  pengiriman  \n",
    "sampah 3. Penerima / pengepul sampah dapat menerima permintaan pengiriman sampah \n",
    "dari pelaku industri \n",
    " \n",
    "Hafidh Husna | Rekayasa Perangkat Lunak \n",
    "4. Kurir  dapat  menerima  permintaan  pengiriman  setelah  permintaan  pengiriman  \n",
    "sudah disetujui oleh kedua belah pihak (pelaku industri dan pengepul sampah). 5. Pengguna umum dapat melakukan verifikasi publikasi artikel edukasi kepada \n",
    "admin 6. Admin dapat melakukan publikasi artikel edukasi 7. Admin dapat melakukan verifikasi permintaan publikasi artikel edukasi yang \n",
    "telah dibuat oleh pengguna umum 8. Aplikasi dapat menampilkan lokasi real-time ketika melakukan tracking proses \n",
    "pengiriman sampah\"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for How to Calculate Manhattan Distance (Data Engineering Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_manhattan_distance():\n",
    "    assert query_and_validate(\n",
    "        question=\"How to calculate manhattan distance?\",\n",
    "        expected_response=\"d(i, j) =|xi1 ‚àí xj1|+|xi2 ‚àí xj2|+¬∑¬∑¬∑+|xip ‚àí xjp |.\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
